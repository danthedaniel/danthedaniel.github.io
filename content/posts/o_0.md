---
title: "O(0)"
date: 2023-06-25T13:36:55-07:00
draft: true
tags: ["programming", "math"]
---

A common tool for measuring the efficiency of an algorithm is [Big O notation](https://en.wikipedia.org/wiki/Big_O_notation). It has a formal mathematical background and is taught today in university classrooms teaching math and computer science. But software engineers also use it as a pragmatic tool. How long will that web page take to load? Well, if the user is uploading 1 or more files and you want to show the files in a sorted order that's going to be, at best

<pre class="math">O(n \log(n))</pre>

So for a given number of files `n`, your load time will be proportional to `n*log(n)`:

| Number of Files | Sorting Time (ms) |
|------:|---------:|
|   1   |   0   |
|  10   |  33   |
|  100  |  664  |
|  1000 |  9966 |

This really matters in the real world. It's not just something for tech interviews. I've blown up a Rails app before because I recklessly added a [Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance) (`O(n*n)` runtime) calculation inside of the page rendering logic.

So given the new breed of users of Big O - the pragmatic engineers - I think we need a new class of time complexity to add to [the table](https://en.wikipedia.org/wiki/Time_complexity#Table_of_common_time_complexities), `O(0)`.

The perfect code is the code with no bugs. And the easiest way to guarantee no bugs is to have **no code**. If you can take a sort out of a webpage entirely you've cut that functionality not to `O(1)`, but rather `O(0)`.

This fits in neatly with a software engineer's golden rules:

1. Thou shalt not prematurely optimize
2. Thou shalt not add features that are not needed

And when I think about this, you can never improve Big O runtime without the existence of `O(0)`. How can sorting go from `O(n*n)` to `O(n*log(n))` when switching from insertion sort to quick sort? You've taken a proportion of the operations and replaced them with a `0`.
